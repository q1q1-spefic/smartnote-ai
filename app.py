# app/app.py

import os
import tempfile
import streamlit as st
from dotenv import load_dotenv

# åŠ è½½æœ¬åœ°ç¯å¢ƒå˜é‡
load_dotenv()

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
import sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from utils.document_processor import DocumentProcessor
from utils.vector_store import VectorStore
from utils.query_engine import QueryEngine

# å°è¯•å¯¼å…¥è¯­éŸ³äº¤äº’æ¨¡å—
voice_interaction_available = False
try:
    from utils.voice_interaction import VoiceInteraction
    voice_interaction_available = True
except ImportError:
    st.sidebar.warning("è¯­éŸ³äº¤äº’æ¨¡å—å¯¼å…¥å¤±è´¥ï¼Œè¯·ç¡®ä¿å·²å®‰è£…ç›¸å…³ä¾èµ–")

# å°è¯•å¯¼å…¥çŸ¥è¯†å›¾è°±æ¨¡å—
knowledge_graph_available = False
try:
    from utils.knowledge_graph import KnowledgeGraph
    knowledge_graph_available = True
except ImportError as e:
    missing_module = str(e).split("'")[1] if "'" in str(e) else str(e)
    st.sidebar.warning(f"çŸ¥è¯†å›¾è°±æ¨¡å—å¯¼å…¥å¤±è´¥: ç¼ºå°‘ {missing_module} æ¨¡å—ã€‚è¯·è¿è¡Œ 'pip install {missing_module}'")

# è®¾ç½®é¡µé¢æ ‡é¢˜å’Œå›¾æ ‡
st.set_page_config(
    page_title="SmartNote AI - ç§äººçŸ¥è¯†é—®ç­”åº“",
    page_icon="ğŸ§ ",
    layout="wide"
)

# åº”ç”¨æ ‡é¢˜
st.title("ğŸ§  SmartNote AI - ç§äººçŸ¥è¯†é—®ç­”åº“")
st.markdown("ä¸Šä¼ ä½ çš„æ–‡æ¡£ï¼Œåˆ›å»ºä½ çš„ç§äººçŸ¥è¯†åº“ï¼Œè®©AIå¸®ä½ è®°ä½å¹¶å›ç­”é—®é¢˜")

# ä¾§è¾¹æ  - é…ç½®
with st.sidebar:
    st.header("âš™ï¸ é…ç½®")
    
    # APIå¯†é’¥è®¾ç½®
    api_key = st.text_input("OpenAI API Key", value=os.environ.get("OPENAI_API_KEY", ""), type="password")
    if api_key:
        os.environ["OPENAI_API_KEY"] = api_key
    
    # åµŒå…¥æ¨¡å‹é€‰æ‹©
    embedding_type = st.selectbox(
        "é€‰æ‹©åµŒå…¥æ¨¡å‹",
        options=["openai", "huggingface"],
        index=0,
        help="OpenAIåµŒå…¥è´¨é‡æ›´é«˜ï¼Œéœ€è¦APIå¯†é’¥ï¼›HuggingFaceæ¨¡å‹å…è´¹ä½†è´¨é‡ç•¥ä½"
    )
    
    # è¯­è¨€æ¨¡å‹é€‰æ‹©
    model_name = st.selectbox(
        "é€‰æ‹©è¯­è¨€æ¨¡å‹",
        options=["gpt-3.5-turbo", "gpt-4"],
        index=0
    )
    
    # åˆ†å—è®¾ç½®
    chunk_size = st.slider("æ–‡æ¡£åˆ†å—å¤§å°", min_value=100, max_value=2000, value=500, step=100)
    chunk_overlap = st.slider("åˆ†å—é‡å å¤§å°", min_value=0, max_value=500, value=50, step=10)
    
    # æ•°æ®åº“è®¾ç½®
    vector_db_type = st.selectbox(
        "å‘é‡æ•°æ®åº“ç±»å‹",
        options=["faiss", "chroma"],
        index=0
    )
    
    # æ•°æ®åº“è·¯å¾„
    db_path = st.text_input("æ•°æ®åº“å­˜å‚¨è·¯å¾„", value="./data/vector_db")

    # è¯­éŸ³è®¾ç½® - ä»…å½“æ¨¡å—å¯ç”¨æ—¶æ˜¾ç¤º
    if voice_interaction_available:
        st.header("ğŸ™ï¸ è¯­éŸ³è®¾ç½®")
        enable_voice = st.checkbox("å¯ç”¨è¯­éŸ³åŠŸèƒ½", value=False)
        if enable_voice:
            voice_type = st.selectbox(
                "é€‰æ‹©è¯­éŸ³ç±»å‹",
                options=["alloy", "echo", "fable", "onyx", "nova", "shimmer"],
                index=0
            )
    else:
        enable_voice = False
    
    # ä¿å­˜æŒ‰é’®
    if st.button("ä¿å­˜é…ç½®"):
        st.success("é…ç½®å·²ä¿å­˜ï¼")

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if 'vector_store' not in st.session_state:
    st.session_state.vector_store = None
if 'query_engine' not in st.session_state:
    st.session_state.query_engine = None
if 'documents_added' not in st.session_state:
    st.session_state.documents_added = False
if 'voice_interaction' not in st.session_state:
    st.session_state.voice_interaction = None
if 'knowledge_graph' not in st.session_state:
    st.session_state.knowledge_graph = None

# åˆ›å»ºæ ‡ç­¾é¡µ - æ ¹æ®å¯ç”¨æ¨¡å—è°ƒæ•´
tabs = ["ğŸ“š ä¸Šä¼ æ–‡æ¡£", "â“ é—®ç­”", "ğŸ“Š çŸ¥è¯†åˆ†æ"]
if knowledge_graph_available:
    tabs.append("ğŸ” çŸ¥è¯†å›¾è°±")

all_tabs = st.tabs(tabs)
tab1 = all_tabs[0]  # ä¸Šä¼ æ–‡æ¡£
tab2 = all_tabs[1]  # é—®ç­”
tab3 = all_tabs[2]  # çŸ¥è¯†åˆ†æ
tab4 = all_tabs[3] if knowledge_graph_available else None  # çŸ¥è¯†å›¾è°±ï¼ˆå¦‚æœå¯ç”¨ï¼‰

# æ ‡ç­¾é¡µ1ï¼šä¸Šä¼ æ–‡æ¡£
with tab1:
    st.header("ğŸ“š ä¸Šä¼ æ–‡æ¡£")
    
    col1, col2 = st.columns(2)
    
    with col1:
        # æ–‡ä»¶ä¸Šä¼ 
        uploaded_files = st.file_uploader("ä¸Šä¼ PDFã€TXTæˆ–Markdownæ–‡ä»¶",
                                         type=["pdf", "txt", "md"],
                                         accept_multiple_files=True)
        
        # æ–‡æ¡£å…ƒæ•°æ®
        doc_category = st.text_input("æ–‡æ¡£åˆ†ç±»", value="", help="ä¾‹å¦‚ï¼šç‰©ç†è¯¾ç¨‹ã€ç¼–ç¨‹ç¬”è®°ç­‰")
        doc_source = st.text_input("æ–‡æ¡£æ¥æº", value="", help="ä¾‹å¦‚ï¼šè¯¾ç¨‹åç§°ã€ä¹¦åç­‰")
    
    with col2:
        # ç½‘é¡µURLè¾“å…¥
        web_url = st.text_input("æˆ–è¾“å…¥ç½‘é¡µURL", value="", help="ä¾‹å¦‚ï¼šhttps://example.com/article")
        
        # å¤„ç†æŒ‰é’®
        process_button = st.button("å¤„ç†æ–‡æ¡£")
    
    # å¤„ç†æ–‡æ¡£
    if process_button and (uploaded_files or web_url):
        # éªŒè¯APIå¯†é’¥
        if not api_key and embedding_type == "openai":
            st.error("è¯·æä¾›OpenAI APIå¯†é’¥ï¼Œæˆ–é€‰æ‹©HuggingFaceåµŒå…¥æ¨¡å‹")
        else:
            with st.spinner("æ­£åœ¨å¤„ç†æ–‡æ¡£..."):
                try:
                    # åˆå§‹åŒ–æ–‡æ¡£å¤„ç†å™¨
                    doc_processor = DocumentProcessor(chunk_size=chunk_size, chunk_overlap=chunk_overlap)
                    
                    # åˆå§‹åŒ–å‘é‡å­˜å‚¨
                    vector_store = VectorStore(embedding_type=embedding_type, api_key=api_key)
                    
                    # ç¡®ä¿ç›®å½•å­˜åœ¨
                    os.makedirs(os.path.dirname(db_path), exist_ok=True)
                    
                    # å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶
                    all_documents = []
                    
                    # å¤„ç†æ–‡ä»¶
                    if uploaded_files:
                        for uploaded_file in uploaded_files:
                            # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
                            with tempfile.NamedTemporaryFile(delete=False, suffix=f".{uploaded_file.name.split('.')[-1]}") as temp_file:
                                temp_file.write(uploaded_file.getbuffer())
                                file_path = temp_file.name
                            
                            # åŠ è½½æ–‡æ¡£
                            docs = doc_processor.load_document(file_path)
                            
                            # æ·»åŠ å…ƒæ•°æ®
                            metadata = {
                                "source": uploaded_file.name,
                                "category": doc_category if doc_category else "æœªåˆ†ç±»",
                                "origin": doc_source if doc_source else "ç”¨æˆ·ä¸Šä¼ "
                            }
                            
                            # å¤„ç†æ–‡æ¡£
                            processed_docs = doc_processor.process_documents(docs, metadata)
                            all_documents.extend(processed_docs)
                            
                            # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
                            os.unlink(file_path)
                    
                    # å¤„ç†ç½‘é¡µ
                    if web_url:
                        try:
                            docs = doc_processor.load_web_page(web_url)
                            
                            # æ·»åŠ å…ƒæ•°æ®
                            metadata = {
                                "source": web_url,
                                "category": doc_category if doc_category else "ç½‘é¡µå†…å®¹",
                                "origin": doc_source if doc_source else "ç½‘é¡µ"
                            }
                            
                            # å¤„ç†æ–‡æ¡£
                            processed_docs = doc_processor.process_documents(docs, metadata)
                            all_documents.extend(processed_docs)
                        except Exception as e:
                            st.error(f"å¤„ç†ç½‘é¡µæ—¶å‡ºé”™: {str(e)}")
                    
                    # å¦‚æœæœ‰å¤„ç†åçš„æ–‡æ¡£ï¼Œåˆ›å»ºå‘é‡å­˜å‚¨
                    if all_documents:
                        # åˆ›å»ºå‘é‡å­˜å‚¨
                        vector_db = vector_store.create_vector_store(
                            all_documents,
                            store_type=vector_db_type,
                            persist_directory=db_path
                        )
                        
                        # ä¿å­˜åˆ°ä¼šè¯çŠ¶æ€
                        st.session_state.vector_store = vector_store
                        
                        # åˆå§‹åŒ–æŸ¥è¯¢å¼•æ“
                        retriever = vector_store.get_retriever()
                        query_engine = QueryEngine(
                            retriever=retriever,
                            model_name=model_name,
                            api_key=api_key
                        )
                        st.session_state.query_engine = query_engine
                        st.session_state.documents_added = True
                        
                        # åˆå§‹åŒ–çŸ¥è¯†å›¾è°± - å¦‚æœæ¨¡å—å¯ç”¨
                        if knowledge_graph_available and api_key:
                            try:
                                from langchain.chat_models import ChatOpenAI
                                llm = ChatOpenAI(model_name=model_name, openai_api_key=api_key)
                                st.session_state.knowledge_graph = KnowledgeGraph(llm=llm)
                            except Exception as e:
                                st.warning(f"åˆå§‹åŒ–çŸ¥è¯†å›¾è°±æ—¶å‡ºé”™: {str(e)}")
                        
                        # åˆå§‹åŒ–è¯­éŸ³äº¤äº’ - å¦‚æœæ¨¡å—å¯ç”¨
                        if voice_interaction_available and enable_voice and api_key:
                            try:
                                st.session_state.voice_interaction = VoiceInteraction(openai_api_key=api_key)
                            except Exception as e:
                                st.warning(f"åˆå§‹åŒ–è¯­éŸ³äº¤äº’æ—¶å‡ºé”™: {str(e)}")
                        
                        st.success(f"æˆåŠŸå¤„ç† {len(all_documents)} ä¸ªæ–‡æ¡£å—ï¼")
                    else:
                        st.warning("æ²¡æœ‰å¤„ç†åˆ°ä»»ä½•æ–‡æ¡£å†…å®¹ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æˆ–URLæ˜¯å¦æœ‰æ•ˆã€‚")
                        
                except Exception as e:
                    st.error(f"å¤„ç†æ–‡æ¡£æ—¶å‡ºé”™: {str(e)}")

    # åŠ è½½ç°æœ‰æ•°æ®åº“
    st.markdown("---")
    if st.button("åŠ è½½ç°æœ‰çŸ¥è¯†åº“"):
        try:
            # éªŒè¯APIå¯†é’¥
            if not api_key and embedding_type == "openai":
                st.error("è¯·æä¾›OpenAI APIå¯†é’¥ï¼Œæˆ–é€‰æ‹©HuggingFaceåµŒå…¥æ¨¡å‹")
            else:
                with st.spinner("æ­£åœ¨åŠ è½½çŸ¥è¯†åº“..."):
                    # æ£€æŸ¥æ•°æ®åº“ç›®å½•æ˜¯å¦å­˜åœ¨
                    if not os.path.exists(db_path):
                        st.error(f"æ•°æ®åº“è·¯å¾„ä¸å­˜åœ¨: {db_path}")
                    else:
                        # åˆå§‹åŒ–å‘é‡å­˜å‚¨
                        vector_store = VectorStore(embedding_type=embedding_type, api_key=api_key)
                        
                        # åŠ è½½å‘é‡å­˜å‚¨
                        vector_db = vector_store.load_vector_store(
                            store_type=vector_db_type,
                            persist_directory=db_path
                        )
                        
                        # ä¿å­˜åˆ°ä¼šè¯çŠ¶æ€
                        st.session_state.vector_store = vector_store
                        
                        # åˆå§‹åŒ–æŸ¥è¯¢å¼•æ“
                        retriever = vector_store.get_retriever()
                        query_engine = QueryEngine(
                            retriever=retriever,
                            model_name=model_name,
                            api_key=api_key
                        )
                        st.session_state.query_engine = query_engine
                        st.session_state.documents_added = True
                        
                        # åˆå§‹åŒ–çŸ¥è¯†å›¾è°± - å¦‚æœæ¨¡å—å¯ç”¨
                        if knowledge_graph_available and api_key:
                            try:
                                from langchain.chat_models import ChatOpenAI
                                llm = ChatOpenAI(model_name=model_name, openai_api_key=api_key)
                                st.session_state.knowledge_graph = KnowledgeGraph(llm=llm)
                            except Exception as e:
                                st.warning(f"åˆå§‹åŒ–çŸ¥è¯†å›¾è°±æ—¶å‡ºé”™: {str(e)}")
                        
                        # åˆå§‹åŒ–è¯­éŸ³äº¤äº’ - å¦‚æœæ¨¡å—å¯ç”¨
                        if voice_interaction_available and enable_voice and api_key:
                            try:
                                st.session_state.voice_interaction = VoiceInteraction(openai_api_key=api_key)
                            except Exception as e:
                                st.warning(f"åˆå§‹åŒ–è¯­éŸ³äº¤äº’æ—¶å‡ºé”™: {str(e)}")
                        
                        st.success("æˆåŠŸåŠ è½½çŸ¥è¯†åº“ï¼")
        except Exception as e:
            st.error(f"åŠ è½½çŸ¥è¯†åº“æ—¶å‡ºé”™: {str(e)}")

# æ ‡ç­¾é¡µ2ï¼šé—®ç­”
with tab2:
    st.header("â“ é—®ç­”")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å‘é‡æ•°æ®åº“
    if not st.session_state.documents_added:
        st.info("è¯·å…ˆä¸Šä¼ æˆ–åŠ è½½æ–‡æ¡£ï¼Œç„¶åå†è¿›è¡Œé—®ç­”ã€‚")
    else:
        # é—®é¢˜è¾“å…¥æ–¹å¼é€‰æ‹© - ä»…å½“è¯­éŸ³æ¨¡å—å¯ç”¨æ—¶æ˜¾ç¤ºé€‰æ‹©
        if voice_interaction_available and st.session_state.voice_interaction:
            input_method = st.radio("é€‰æ‹©è¾“å…¥æ–¹å¼", ["æ–‡æœ¬è¾“å…¥", "è¯­éŸ³è¾“å…¥"], horizontal=True)
        else:
            input_method = "æ–‡æœ¬è¾“å…¥"
        
        if input_method == "æ–‡æœ¬è¾“å…¥":
            # é—®é¢˜è¾“å…¥
            question = st.text_input("è¾“å…¥ä½ çš„é—®é¢˜", help="ä¾‹å¦‚ï¼šä»€ä¹ˆæ˜¯çƒ­åŠ›å­¦ç¬¬äºŒå®šå¾‹ï¼Ÿ")
        else:
            # è¯­éŸ³è¾“å…¥
            st.info("ç‚¹å‡»ä¸‹æ–¹æŒ‰é’®ï¼Œç„¶åè¯´å‡ºä½ çš„é—®é¢˜")
            audio_bytes = st.audio_recorder(
                sample_rate=16000,
                key="voice_input"
            )
            
            if audio_bytes:
                try:
                    from io import BytesIO
                    audio_file = BytesIO(audio_bytes)
                    with st.spinner("æ­£åœ¨è½¬å½•è¯­éŸ³..."):
                        question = st.session_state.voice_interaction.speech_to_text(audio_file)
                        st.success(f"å·²è¯†åˆ«é—®é¢˜: {question}")
                except Exception as e:
                    st.error(f"è¯­éŸ³è½¬å½•å¤±è´¥: {str(e)}")
                    question = ""
            else:
                question = ""
        
        # è¯­éŸ³è¾“å‡ºé€‰é¡¹ - ä»…å½“è¯­éŸ³æ¨¡å—å¯ç”¨æ—¶æ˜¾ç¤º
        if voice_interaction_available and st.session_state.voice_interaction:
            enable_voice_output = st.checkbox("å¯ç”¨è¯­éŸ³å›ç­”", value=False)
        else:
            enable_voice_output = False
            
        # æŸ¥è¯¢æŒ‰é’®
        if st.button("æé—®") and question:
            with st.spinner("æ€è€ƒä¸­..."):
                try:
                    # æŸ¥è¯¢
                    result = st.session_state.query_engine.query(question)
                    
                    # æ˜¾ç¤ºå›ç­”
                    st.markdown("### å›ç­”")
                    answer_text = result["answer"]
                    st.write(answer_text)
                    
                    # è¯­éŸ³å›ç­” - ä»…å½“å¯ç”¨è¯­éŸ³è¾“å‡ºä¸”è¯­éŸ³æ¨¡å—å¯ç”¨æ—¶
                    if enable_voice_output and voice_interaction_available and st.session_state.voice_interaction:
                        try:
                            with st.spinner("ç”Ÿæˆè¯­éŸ³å›ç­”..."):
                                # å°†æ–‡æœ¬åˆ†æˆå°æ®µä»¥é€‚åº”APIé™åˆ¶
                                max_length = 4000
                                answer_chunks = [answer_text[i:i+max_length] for i in range(0, len(answer_text), max_length)]
                                
                                for i, chunk in enumerate(answer_chunks):
                                    audio_content, content_type = st.session_state.voice_interaction.text_to_speech(chunk)
                                    if audio_content and content_type:
                                        st.audio(audio_content, format=content_type)
                                    else:
                                        st.warning("æ— æ³•ç”Ÿæˆè¯­éŸ³å›ç­”")
                                        break
                        except Exception as e:
                            st.error(f"ç”Ÿæˆè¯­éŸ³å¤±è´¥: {str(e)}")
                    
                    # æ˜¾ç¤ºæ¥æº
                    st.markdown("### å‚è€ƒæ¥æº")
                    for i, doc in enumerate(result["source_documents"]):
                        with st.expander(f"æ¥æº {i+1} ({doc.metadata.get('source', 'æœªçŸ¥æ¥æº')})"):
                            st.markdown(doc.page_content)
                            st.markdown(f"**åˆ†ç±»**: {doc.metadata.get('category', 'æœªåˆ†ç±»')}")
                            st.markdown(f"**æ¥æº**: {doc.metadata.get('origin', 'æœªçŸ¥')}")
                            
                except Exception as e:
                    st.error(f"æŸ¥è¯¢è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")

# æ ‡ç­¾é¡µ3ï¼šçŸ¥è¯†åˆ†æ
with tab3:
    st.header("ğŸ“Š çŸ¥è¯†åˆ†æ")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å‘é‡æ•°æ®åº“
    if not st.session_state.documents_added:
        st.info("è¯·å…ˆä¸Šä¼ æˆ–åŠ è½½æ–‡æ¡£ï¼Œç„¶åå†è¿›è¡ŒçŸ¥è¯†åˆ†æã€‚")
    else:
        # é€‰æ‹©åˆ†æç±»å‹
        analysis_type = st.radio(
            "é€‰æ‹©åˆ†æç±»å‹",
            ["ç”Ÿæˆæ‘˜è¦", "æå–å…³é”®ç‚¹"]
        )
        
        # ä¸»é¢˜æˆ–å…³é”®è¯
        topic = st.text_input("è¾“å…¥ä¸»é¢˜æˆ–å…³é”®è¯", help="ä¾‹å¦‚ï¼šæœºå™¨å­¦ä¹ ã€é‡å­ç‰©ç†")
        
        # åˆ†ææŒ‰é’®
        if st.button("åˆ†æ") and topic:
            with st.spinner("åˆ†æä¸­..."):
                try:
                    # è·å–ç›¸å…³æ–‡æ¡£
                    retriever = st.session_state.vector_store.get_retriever({"k": 8})
                    docs = retriever.get_relevant_documents(topic)
                    
                    if not docs:
                        st.warning(f"æœªæ‰¾åˆ°ä¸'{topic}'ç›¸å…³çš„å†…å®¹ã€‚")
                    else:
                        if analysis_type == "ç”Ÿæˆæ‘˜è¦":
                            # ç”Ÿæˆæ‘˜è¦
                            summary = st.session_state.query_engine.generate_summary(docs)
                            
                            # æ˜¾ç¤ºæ‘˜è¦
                            st.markdown("### å…³äº " + topic + " çš„æ‘˜è¦")
                            st.write(summary)
                            
                        elif analysis_type == "æå–å…³é”®ç‚¹":
                            # æå–å…³é”®ç‚¹
                            key_points = st.session_state.query_engine.extract_key_points(docs)
                            
                            # æ˜¾ç¤ºå…³é”®ç‚¹
                            st.markdown("### å…³äº " + topic + " çš„å…³é”®ç‚¹")
                            for i, point in enumerate(key_points):
                                st.markdown(f"**{i+1}.** {point}")
                        
                        # æ˜¾ç¤ºæ¥æºæ–‡æ¡£æ•°é‡
                        st.info(f"åˆ†æåŸºäº {len(docs)} ä¸ªç›¸å…³æ–‡æ¡£å—")
                        
                except Exception as e:
                    st.error(f"åˆ†æè¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")

# æ ‡ç­¾é¡µ4ï¼šçŸ¥è¯†å›¾è°± - ä»…å½“æ¨¡å—å¯ç”¨æ—¶æ˜¾ç¤º
if knowledge_graph_available and tab4:
    with tab4:
        st.header("ğŸ” çŸ¥è¯†å›¾è°±")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å‘é‡æ•°æ®åº“å’ŒAPIå¯†é’¥
        if not st.session_state.documents_added:
            st.info("è¯·å…ˆä¸Šä¼ æˆ–åŠ è½½æ–‡æ¡£ï¼Œç„¶åå†ç”ŸæˆçŸ¥è¯†å›¾è°±ã€‚")
        elif not api_key:
            st.warning("ç”ŸæˆçŸ¥è¯†å›¾è°±éœ€è¦OpenAI APIå¯†é’¥ï¼Œè¯·åœ¨é…ç½®ä¸­æä¾›ã€‚")
        elif not st.session_state.knowledge_graph:
            st.warning("çŸ¥è¯†å›¾è°±æ¨¡å—æœªåˆå§‹åŒ–ï¼Œè¯·ç¡®ä¿APIå¯†é’¥æ­£ç¡®ï¼Œç„¶åé‡æ–°åŠ è½½çŸ¥è¯†åº“ã€‚")
        else:
            # ä¸»é¢˜æˆ–å…³é”®è¯
            graph_topic = st.text_input("è¾“å…¥è¦ç”ŸæˆçŸ¥è¯†å›¾è°±çš„ä¸»é¢˜æˆ–å…³é”®è¯", help="ä¾‹å¦‚ï¼šäººå·¥æ™ºèƒ½ã€æ°”å€™å˜åŒ–")
            
            # è®¾ç½®
            col1, col2 = st.columns(2)
            with col1:
                doc_count = st.slider("æ£€ç´¢æ–‡æ¡£æ•°é‡", min_value=3, max_value=15, value=5, step=1)
            with col2:
                entity_limit = st.slider("å®ä½“æ•°é‡é™åˆ¶", min_value=5, max_value=20, value=10, step=1)
            
            # ç”ŸæˆæŒ‰é’®
            if st.button("ç”ŸæˆçŸ¥è¯†å›¾è°±") and graph_topic:
                with st.spinner("æ­£åœ¨ç”ŸæˆçŸ¥è¯†å›¾è°±..."):
                    try:
                        # è·å–ç›¸å…³æ–‡æ¡£
                        retriever = st.session_state.vector_store.get_retriever({"k": doc_count})
                        docs = retriever.get_relevant_documents(graph_topic)
                        
                        if not docs:
                            st.warning(f"æœªæ‰¾åˆ°ä¸'{graph_topic}'ç›¸å…³çš„å†…å®¹ã€‚")
                        else:
                            # æå–å®ä½“å’Œå…³ç³»
                            relations = st.session_state.knowledge_graph.extract_entities_and_relations(docs)
                            
                            if not relations:
                                st.warning("æœªèƒ½æå–å‡ºå®ä½“å’Œå…³ç³»ï¼Œè¯·å°è¯•å…¶ä»–ä¸»é¢˜æˆ–å…³é”®è¯ã€‚")
                            else:
                                # é™åˆ¶å®ä½“æ•°é‡ä»¥é¿å…å›¾è¿‡äºå¤æ‚
                                if len(relations) > entity_limit:
                                    relations = relations[:entity_limit]
                                    
                                # æ„å»ºå›¾
                                graph = st.session_state.knowledge_graph.build_graph(relations)
                                
                                # æ˜¾ç¤ºå›¾
                                try:
                                    fig = st.session_state.knowledge_graph.visualize_plotly(graph)
                                    st.plotly_chart(fig, use_container_width=True)
                                    
                                    # æ˜¾ç¤ºä¸­å¿ƒæ¦‚å¿µ
                                    central_concepts = st.session_state.knowledge_graph.get_central_concepts()
                                    if central_concepts:
                                        st.markdown("### ä¸­å¿ƒæ¦‚å¿µ")
                                        for concept, score in central_concepts:
                                            st.markdown(f"- **{concept}** (é‡è¦æ€§å¾—åˆ†: {score:.2f})")
                                except Exception as e:
                                    st.error(f"å¯è§†åŒ–å›¾è°±æ—¶å‡ºé”™: {str(e)}")
                                    
                                # æ˜¾ç¤ºå¤„ç†çš„æ–‡æ¡£æ•°
                                st.info(f"çŸ¥è¯†å›¾è°±åŸºäº {len(docs)} ä¸ªç›¸å…³æ–‡æ¡£å—ï¼ŒåŒ…å« {len(graph.nodes())} ä¸ªå®ä½“å’Œ {len(graph.edges())} ä¸ªå…³ç³»ã€‚")
                    
                    except Exception as e:
                        st.error(f"ç”ŸæˆçŸ¥è¯†å›¾è°±æ—¶å‡ºé”™: {str(e)}")
                        
            # çŸ¥è¯†å›¾è°±çš„è¯´æ˜
            with st.expander("ä»€ä¹ˆæ˜¯çŸ¥è¯†å›¾è°±ï¼Ÿ"):
                st.markdown("""
                **çŸ¥è¯†å›¾è°±**æ˜¯ä»¥å›¾çš„å½¢å¼å‘ˆç°çŸ¥è¯†çš„ç»“æ„åŒ–è¡¨ç¤ºï¼Œç”±å®ä½“ï¼ˆèŠ‚ç‚¹ï¼‰å’Œå…³ç³»ï¼ˆè¾¹ï¼‰ç»„æˆã€‚
                
                åœ¨SmartNote AIä¸­ï¼ŒçŸ¥è¯†å›¾è°±å¸®åŠ©ä½ :
                - ç›´è§‚åœ°äº†è§£æ–‡æ¡£ä¸­çš„å…³é”®æ¦‚å¿µåŠå…¶å…³ç³»
                - å‘ç°æ½œåœ¨çš„çŸ¥è¯†è”ç³»
                - è¯†åˆ«é‡è¦çš„ä¸­å¿ƒæ¦‚å¿µ
                
                ä½¿ç”¨æ–¹æ³•ï¼šè¾“å…¥ä¸€ä¸ªä¸»é¢˜æˆ–å…³é”®è¯ï¼Œç³»ç»Ÿä¼šåœ¨ä½ çš„çŸ¥è¯†åº“ä¸­æ£€ç´¢ç›¸å…³å†…å®¹ï¼Œç„¶åæå–å‡ºå®ä½“å’Œå…³ç³»ï¼Œä»¥äº¤äº’å¼å›¾è¡¨çš„å½¢å¼å±•ç¤ºã€‚
                """)

# é¡µè„š
st.markdown("---")
st.markdown("*SmartNote AI - è®©çŸ¥è¯†æ°¸è¿œè§¦æ‰‹å¯åŠ* ğŸš€")
