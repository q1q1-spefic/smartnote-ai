# app/app.py

import os
import tempfile
import streamlit as st
from dotenv import load_dotenv

# Try to load API key from Streamlit secrets first
if 'OPENAI_API_KEY' in st.secrets:
    os.environ['OPENAI_API_KEY'] = st.secrets['OPENAI_API_KEY']
# Then try to load from local .env file
else:
    load_dotenv()

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
import sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from utils.document_processor import DocumentProcessor
from utils.vector_store import VectorStore
from utils.query_engine import QueryEngine

# å°è¯•å¯¼å…¥è¯­éŸ³äº¤äº’æ¨¡å—
voice_interaction_available = False
try:
    from utils.voice_interaction import VoiceInteraction
    voice_interaction_available = True
except ImportError:
    st.sidebar.warning("Voice interaction module failed to import. Please ensure dependencies are installed.")

# å°è¯•å¯¼å…¥çŸ¥è¯†å›¾è°±æ¨¡å—
knowledge_graph_available = False
try:
    from utils.knowledge_graph import KnowledgeGraph
    knowledge_graph_available = True
except ImportError as e:
    missing_module = str(e).split("'")[1] if "'" in str(e) else str(e)
    st.sidebar.warning(f"Knowledge graph module failed to import: Missing {missing_module} module. Please run 'pip install {missing_module}'")

# è®¾ç½®é¡µé¢æ ‡é¢˜å’Œå›¾æ ‡
st.set_page_config(
    page_title="SmartNote AI - Personal Knowledge Base",
    page_icon="ğŸ§ ",
    layout="wide"
)

# Apply English font to entire app
st.markdown("""
<style>
    * {
        font-family: 'Arial', 'Helvetica', sans-serif;
    }
    h1, h2, h3, h4, h5, h6 {
        font-family: 'Arial', 'Helvetica', sans-serif;
    }
</style>
""", unsafe_allow_html=True)

# åº”ç”¨æ ‡é¢˜
st.title("ğŸ§  SmartNote AI - Personal Knowledge Base")
st.markdown("Upload your documents, create your personal knowledge base, and let AI remember and answer questions for you")

# ä¾§è¾¹æ  - é…ç½®
with st.sidebar:
    st.header("âš™ï¸ Configuration")
    
    # APIå¯†é’¥è®¾ç½® - ä¿®æ”¹æ­¤éƒ¨åˆ†
    api_key = st.text_input("OpenAI API Key",
                           value=os.environ.get("OPENAI_API_KEY", ""),
                           type="password",
                           help="Leave blank if deployed on Streamlit Cloud with secrets configured")
    if api_key:
        os.environ["OPENAI_API_KEY"] = api_key
    
    # åµŒå…¥æ¨¡å‹é€‰æ‹©
    embedding_type = st.selectbox(
        "Select Embedding Model",
        options=["openai", "huggingface"],
        index=0,
        help="OpenAI embeddings are higher quality but require API key; HuggingFace models are free but lower quality"
    )
    
    # è¯­è¨€æ¨¡å‹é€‰æ‹©
    model_name = st.selectbox(
        "Select Language Model",
        options=["gpt-3.5-turbo", "gpt-4"],
        index=0
    )
    
    # åˆ†å—è®¾ç½®
    chunk_size = st.slider("Document Chunk Size", min_value=100, max_value=2000, value=500, step=100)
    chunk_overlap = st.slider("Chunk Overlap Size", min_value=0, max_value=500, value=50, step=10)
    
    # æ•°æ®åº“è®¾ç½®
    vector_db_type = st.selectbox(
        "Vector Database Type",
        options=["faiss", "chroma"],
        index=0
    )
    
    # æ•°æ®åº“è·¯å¾„
    db_path = st.text_input("Database Storage Path", value="./data/vector_db")

    # è¯­éŸ³è®¾ç½® - ä»…å½“æ¨¡å—å¯ç”¨æ—¶æ˜¾ç¤º
    if voice_interaction_available:
        st.header("ğŸ™ï¸ Voice Settings")
        enable_voice = st.checkbox("Enable Voice Features", value=False)
        if enable_voice:
            voice_type = st.selectbox(
                "Select Voice Type",
                options=["alloy", "echo", "fable", "onyx", "nova", "shimmer"],
                index=0
            )
    else:
        enable_voice = False
    
    # ä¿å­˜æŒ‰é’®
    if st.button("Save Configuration"):
        st.success("Configuration saved!")

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if 'vector_store' not in st.session_state:
    st.session_state.vector_store = None
if 'query_engine' not in st.session_state:
    st.session_state.query_engine = None
if 'documents_added' not in st.session_state:
    st.session_state.documents_added = False
if 'voice_interaction' not in st.session_state:
    st.session_state.voice_interaction = None
if 'knowledge_graph' not in st.session_state:
    st.session_state.knowledge_graph = None

# åˆ›å»ºæ ‡ç­¾é¡µ - æ ¹æ®å¯ç”¨æ¨¡å—è°ƒæ•´
tabs = ["ğŸ“š Upload Documents", "â“ Q&A", "ğŸ“Š Knowledge Analysis"]
if knowledge_graph_available:
    tabs.append("ğŸ” Knowledge Graph")

all_tabs = st.tabs(tabs)
tab1 = all_tabs[0]  # ä¸Šä¼ æ–‡æ¡£
tab2 = all_tabs[1]  # é—®ç­”
tab3 = all_tabs[2]  # çŸ¥è¯†åˆ†æ
tab4 = all_tabs[3] if knowledge_graph_available else None  # çŸ¥è¯†å›¾è°±ï¼ˆå¦‚æœå¯ç”¨ï¼‰

# æ ‡ç­¾é¡µ1ï¼šä¸Šä¼ æ–‡æ¡£
with tab1:
    st.header("ğŸ“š Upload Documents")
    
    col1, col2 = st.columns(2)
    
    with col1:
        # æ–‡ä»¶ä¸Šä¼ 
        uploaded_files = st.file_uploader("Upload PDF, TXT or Markdown files",
                                         type=["pdf", "txt", "md"],
                                         accept_multiple_files=True)
        
        # æ–‡æ¡£å…ƒæ•°æ®
        doc_category = st.text_input("Document Category", value="", help="E.g.: Physics course, Programming notes, etc.")
        doc_source = st.text_input("Document Source", value="", help="E.g.: Course name, Book title, etc.")
    
    with col2:
        # ç½‘é¡µURLè¾“å…¥
        web_url = st.text_input("Or enter a web page URL", value="", help="E.g.: https://example.com/article")
        
        # å¤„ç†æŒ‰é’®
        process_button = st.button("Process Documents")
    
    # å¤„ç†æ–‡æ¡£
    if process_button and (uploaded_files or web_url):
        # éªŒè¯APIå¯†é’¥
        if not os.environ.get("OPENAI_API_KEY") and embedding_type == "openai":
            st.error("Please provide an OpenAI API key, or select HuggingFace embedding model")
        else:
            with st.spinner("Processing documents..."):
                try:
                    # åˆå§‹åŒ–æ–‡æ¡£å¤„ç†å™¨
                    doc_processor = DocumentProcessor(chunk_size=chunk_size, chunk_overlap=chunk_overlap)
                    
                    # åˆå§‹åŒ–å‘é‡å­˜å‚¨
                    vector_store = VectorStore(embedding_type=embedding_type, api_key=os.environ.get("OPENAI_API_KEY", ""))
                    
                    # ç¡®ä¿ç›®å½•å­˜åœ¨
                    os.makedirs(os.path.dirname(db_path), exist_ok=True)
                    
                    # å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶
                    all_documents = []
                    
                    # å¤„ç†æ–‡ä»¶
                    if uploaded_files:
                        for uploaded_file in uploaded_files:
                            # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
                            with tempfile.NamedTemporaryFile(delete=False, suffix=f".{uploaded_file.name.split('.')[-1]}") as temp_file:
                                temp_file.write(uploaded_file.getbuffer())
                                file_path = temp_file.name
                            
                            # åŠ è½½æ–‡æ¡£
                            docs = doc_processor.load_document(file_path)
                            
                            # æ·»åŠ å…ƒæ•°æ®
                            metadata = {
                                "source": uploaded_file.name,
                                "category": doc_category if doc_category else "Uncategorized",
                                "origin": doc_source if doc_source else "User Upload"
                            }
                            
                            # å¤„ç†æ–‡æ¡£
                            processed_docs = doc_processor.process_documents(docs, metadata)
                            all_documents.extend(processed_docs)
                            
                            # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
                            os.unlink(file_path)
                    
                    # å¤„ç†ç½‘é¡µ
                    if web_url:
                        try:
                            docs = doc_processor.load_web_page(web_url)
                            
                            # æ·»åŠ å…ƒæ•°æ®
                            metadata = {
                                "source": web_url,
                                "category": doc_category if doc_category else "Web Content",
                                "origin": doc_source if doc_source else "Web Page"
                            }
                            
                            # å¤„ç†æ–‡æ¡£
                            processed_docs = doc_processor.process_documents(docs, metadata)
                            all_documents.extend(processed_docs)
                        except Exception as e:
                            st.error(f"Error processing web page: {str(e)}")
                    
                    # å¦‚æœæœ‰å¤„ç†åçš„æ–‡æ¡£ï¼Œåˆ›å»ºå‘é‡å­˜å‚¨
                    if all_documents:
                        # åˆ›å»ºå‘é‡å­˜å‚¨
                        vector_db = vector_store.create_vector_store(
                            all_documents,
                            store_type=vector_db_type,
                            persist_directory=db_path
                        )
                        
                        # ä¿å­˜åˆ°ä¼šè¯çŠ¶æ€
                        st.session_state.vector_store = vector_store
                        
                        # åˆå§‹åŒ–æŸ¥è¯¢å¼•æ“
                        retriever = vector_store.get_retriever()
                        query_engine = QueryEngine(
                            retriever=retriever,
                            model_name=model_name,
                            api_key=os.environ.get("OPENAI_API_KEY", "")
                        )
                        st.session_state.query_engine = query_engine
                        st.session_state.documents_added = True
                        
                        # åˆå§‹åŒ–çŸ¥è¯†å›¾è°± - å¦‚æœæ¨¡å—å¯ç”¨
                        if knowledge_graph_available and os.environ.get("OPENAI_API_KEY"):
                            try:
                                from langchain.chat_models import ChatOpenAI
                                llm = ChatOpenAI(model_name=model_name, openai_api_key=os.environ.get("OPENAI_API_KEY"))
                                st.session_state.knowledge_graph = KnowledgeGraph(llm=llm)
                            except Exception as e:
                                st.warning(f"Error initializing knowledge graph: {str(e)}")
                        
                        # åˆå§‹åŒ–è¯­éŸ³äº¤äº’ - å¦‚æœæ¨¡å—å¯ç”¨
                        if voice_interaction_available and enable_voice and os.environ.get("OPENAI_API_KEY"):
                            try:
                                st.session_state.voice_interaction = VoiceInteraction(openai_api_key=os.environ.get("OPENAI_API_KEY"))
                            except Exception as e:
                                st.warning(f"Error initializing voice interaction: {str(e)}")
                        
                        st.success(f"Successfully processed {len(all_documents)} document chunks!")
                    else:
                        st.warning("No document content was processed. Please check if the file or URL is valid.")
                        
                except Exception as e:
                    st.error(f"Error processing documents: {str(e)}")

    # åŠ è½½ç°æœ‰æ•°æ®åº“
    st.markdown("---")
    if st.button("Load Existing Knowledge Base"):
        try:
            # éªŒè¯APIå¯†é’¥
            if not os.environ.get("OPENAI_API_KEY") and embedding_type == "openai":
                st.error("Please provide an OpenAI API key, or select HuggingFace embedding model")
            else:
                with st.spinner("Loading knowledge base..."):
                    # æ£€æŸ¥æ•°æ®åº“ç›®å½•æ˜¯å¦å­˜åœ¨
                    if not os.path.exists(db_path):
                        st.error(f"Database path doesn't exist: {db_path}")
                    else:
                        # åˆå§‹åŒ–å‘é‡å­˜å‚¨
                        vector_store = VectorStore(embedding_type=embedding_type, api_key=os.environ.get("OPENAI_API_KEY", ""))
                        
                        # åŠ è½½å‘é‡å­˜å‚¨
                        vector_db = vector_store.load_vector_store(
                            store_type=vector_db_type,
                            persist_directory=db_path
                        )
                        
                        # ä¿å­˜åˆ°ä¼šè¯çŠ¶æ€
                        st.session_state.vector_store = vector_store
                        
                        # åˆå§‹åŒ–æŸ¥è¯¢å¼•æ“
                        retriever = vector_store.get_retriever()
                        query_engine = QueryEngine(
                            retriever=retriever,
                            model_name=model_name,
                            api_key=os.environ.get("OPENAI_API_KEY", "")
                        )
                        st.session_state.query_engine = query_engine
                        st.session_state.documents_added = True
                        
                        # åˆå§‹åŒ–çŸ¥è¯†å›¾è°± - å¦‚æœæ¨¡å—å¯ç”¨
                        if knowledge_graph_available and os.environ.get("OPENAI_API_KEY"):
                            try:
                                from langchain.chat_models import ChatOpenAI
                                llm = ChatOpenAI(model_name=model_name, openai_api_key=os.environ.get("OPENAI_API_KEY"))
                                st.session_state.knowledge_graph = KnowledgeGraph(llm=llm)
                            except Exception as e:
                                st.warning(f"Error initializing knowledge graph: {str(e)}")
                        
                        # åˆå§‹åŒ–è¯­éŸ³äº¤äº’ - å¦‚æœæ¨¡å—å¯ç”¨
                        if voice_interaction_available and enable_voice and os.environ.get("OPENAI_API_KEY"):
                            try:
                                st.session_state.voice_interaction = VoiceInteraction(openai_api_key=os.environ.get("OPENAI_API_KEY"))
                            except Exception as e:
                                st.warning(f"Error initializing voice interaction: {str(e)}")
                        
                        st.success("Successfully loaded knowledge base!")
        except Exception as e:
            st.error(f"Error loading knowledge base: {str(e)}")

# æ ‡ç­¾é¡µ2ï¼šé—®ç­”
with tab2:
    st.header("â“ Q&A")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å‘é‡æ•°æ®åº“
    if not st.session_state.documents_added:
        st.info("Please upload or load documents first before asking questions.")
    else:
        # é—®é¢˜è¾“å…¥æ–¹å¼é€‰æ‹© - ä»…å½“è¯­éŸ³æ¨¡å—å¯ç”¨æ—¶æ˜¾ç¤ºé€‰æ‹©
        if voice_interaction_available and st.session_state.voice_interaction:
            input_method = st.radio("Select input method", ["Text Input", "Voice Input"], horizontal=True)
        else:
            input_method = "Text Input"
        
        if input_method == "Text Input":
            # é—®é¢˜è¾“å…¥
            question = st.text_input("Enter your question", help="E.g.: What is the second law of thermodynamics?")
        else:
            # è¯­éŸ³è¾“å…¥
            st.info("Click the button below and speak your question")
            audio_bytes = st.audio_recorder(
                sample_rate=16000,
                key="voice_input"
            )
            
            if audio_bytes:
                try:
                    from io import BytesIO
                    audio_file = BytesIO(audio_bytes)
                    with st.spinner("Transcribing speech..."):
                        question = st.session_state.voice_interaction.speech_to_text(audio_file)
                        st.success(f"Recognized question: {question}")
                except Exception as e:
                    st.error(f"Speech transcription failed: {str(e)}")
                    question = ""
            else:
                question = ""
        
        # è¯­éŸ³è¾“å‡ºé€‰é¡¹ - ä»…å½“è¯­éŸ³æ¨¡å—å¯ç”¨æ—¶æ˜¾ç¤º
        if voice_interaction_available and st.session_state.voice_interaction:
            enable_voice_output = st.checkbox("Enable voice response", value=False)
        else:
            enable_voice_output = False
            
        # æŸ¥è¯¢æŒ‰é’®
        if st.button("Ask") and question:
            with st.spinner("Thinking..."):
                try:
                    # æŸ¥è¯¢
                    result = st.session_state.query_engine.query(question)
                    
                    # æ˜¾ç¤ºå›ç­”
                    st.markdown("### Answer")
                    answer_text = result["answer"]
                    st.write(answer_text)
                    
                    # è¯­éŸ³å›ç­” - ä»…å½“å¯ç”¨è¯­éŸ³è¾“å‡ºä¸”è¯­éŸ³æ¨¡å—å¯ç”¨æ—¶
                    if enable_voice_output and voice_interaction_available and st.session_state.voice_interaction:
                        try:
                            with st.spinner("Generating voice response..."):
                                # å°†æ–‡æœ¬åˆ†æˆå°æ®µä»¥é€‚åº”APIé™åˆ¶
                                max_length = 4000
                                answer_chunks = [answer_text[i:i+max_length] for i in range(0, len(answer_text), max_length)]
                                
                                for i, chunk in enumerate(answer_chunks):
                                    audio_content, content_type = st.session_state.voice_interaction.text_to_speech(chunk)
                                    if audio_content and content_type:
                                        st.audio(audio_content, format=content_type)
                                    else:
                                        st.warning("Could not generate voice response")
                                        break
                        except Exception as e:
                            st.error(f"Failed to generate speech: {str(e)}")
                    
                    # æ˜¾ç¤ºæ¥æº
                    st.markdown("### References")
                    for i, doc in enumerate(result["source_documents"]):
                        with st.expander(f"Source {i+1} ({doc.metadata.get('source', 'Unknown source')})"):
                            st.markdown(doc.page_content)
                            st.markdown(f"**Category**: {doc.metadata.get('category', 'Uncategorized')}")
                            st.markdown(f"**Origin**: {doc.metadata.get('origin', 'Unknown')}")
                            
                except Exception as e:
                    st.error(f"Error during query: {str(e)}")

# æ ‡ç­¾é¡µ3ï¼šçŸ¥è¯†åˆ†æ
with tab3:
    st.header("ğŸ“Š Knowledge Analysis")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å‘é‡æ•°æ®åº“
    if not st.session_state.documents_added:
        st.info("Please upload or load documents first before performing knowledge analysis.")
    else:
        # é€‰æ‹©åˆ†æç±»å‹
        analysis_type = st.radio(
            "Select analysis type",
            ["Generate Summary", "Extract Key Points"]
        )
        
        # ä¸»é¢˜æˆ–å…³é”®è¯
        topic = st.text_input("Enter topic or keyword", help="E.g.: Machine Learning, Quantum Physics")
        
        # åˆ†ææŒ‰é’®
        if st.button("Analyze") and topic:
            with st.spinner("Analyzing..."):
                try:
                    # è·å–ç›¸å…³æ–‡æ¡£
                    retriever = st.session_state.vector_store.get_retriever({"k": 8})
                    docs = retriever.get_relevant_documents(topic)
                    
                    if not docs:
                        st.warning(f"No content related to '{topic}' was found.")
                    else:
                        if analysis_type == "Generate Summary":
                            # ç”Ÿæˆæ‘˜è¦
                            summary = st.session_state.query_engine.generate_summary(docs)
                            
                            # æ˜¾ç¤ºæ‘˜è¦
                            st.markdown("### Summary about " + topic)
                            st.write(summary)
                            
                        elif analysis_type == "Extract Key Points":
                            # æå–å…³é”®ç‚¹
                            key_points = st.session_state.query_engine.extract_key_points(docs)
                            
                            # æ˜¾ç¤ºå…³é”®ç‚¹
                            st.markdown("### Key points about " + topic)
                            for i, point in enumerate(key_points):
                                st.markdown(f"**{i+1}.** {point}")
                        
                        # æ˜¾ç¤ºæ¥æºæ–‡æ¡£æ•°é‡
                        st.info(f"Analysis based on {len(docs)} relevant document chunks")
                        
                except Exception as e:
                    st.error(f"Error during analysis: {str(e)}")

# æ ‡ç­¾é¡µ4ï¼šçŸ¥è¯†å›¾è°± - ä»…å½“æ¨¡å—å¯ç”¨æ—¶æ˜¾ç¤º
if knowledge_graph_available and tab4:
    with tab4:
        st.header("ğŸ” Knowledge Graph")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å‘é‡æ•°æ®åº“å’ŒAPIå¯†é’¥
        if not st.session_state.documents_added:
            st.info("Please upload or load documents first before generating a knowledge graph.")
        elif not os.environ.get("OPENAI_API_KEY"):
            st.warning("Generating a knowledge graph requires an OpenAI API key. Please provide one in the configuration.")
        elif not st.session_state.knowledge_graph:
            st.warning("Knowledge graph module not initialized. Please ensure API key is correct and reload the knowledge base.")
        else:
            # ä¸»é¢˜æˆ–å…³é”®è¯
            graph_topic = st.text_input("Enter topic or keyword for knowledge graph", help="E.g.: Artificial Intelligence, Climate Change")
            
            # è®¾ç½®
            col1, col2 = st.columns(2)
            with col1:
                doc_count = st.slider("Number of documents to retrieve", min_value=3, max_value=15, value=5, step=1)
            with col2:
                entity_limit = st.slider("Entity count limit", min_value=5, max_value=20, value=10, step=1)
            
            # ç”ŸæˆæŒ‰é’®
            if st.button("Generate Knowledge Graph") and graph_topic:
                with st.spinner("Generating knowledge graph..."):
                    try:
                        # è·å–ç›¸å…³æ–‡æ¡£
                        retriever = st.session_state.vector_store.get_retriever({"k": doc_count})
                        docs = retriever.get_relevant_documents(graph_topic)
                        
                        if not docs:
                            st.warning(f"No content related to '{graph_topic}' was found.")
                        else:
                            # æå–å®ä½“å’Œå…³ç³»
                            relations = st.session_state.knowledge_graph.extract_entities_and_relations(docs)
                            
                            if not relations:
                                st.warning("Could not extract entities and relations. Please try another topic or keyword.")
                            else:
                                # é™åˆ¶å®ä½“æ•°é‡ä»¥é¿å…å›¾è¿‡äºå¤æ‚
                                if len(relations) > entity_limit:
                                    relations = relations[:entity_limit]
                                    
                                # æ„å»ºå›¾
                                graph = st.session_state.knowledge_graph.build_graph(relations)
                                
                                # æ˜¾ç¤ºå›¾
                                try:
                                    fig = st.session_state.knowledge_graph.visualize_plotly(graph)
                                    st.plotly_chart(fig, use_container_width=True)
                                    
                                    # æ˜¾ç¤ºä¸­å¿ƒæ¦‚å¿µ
                                    central_concepts = st.session_state.knowledge_graph.get_central_concepts()
                                    if central_concepts:
                                        st.markdown("### Central Concepts")
                                        for concept, score in central_concepts:
                                            st.markdown(f"- **{concept}** (Importance score: {score:.2f})")
                                except Exception as e:
                                    st.error(f"Error visualizing graph: {str(e)}")
                                    
                                # æ˜¾ç¤ºå¤„ç†çš„æ–‡æ¡£æ•°
                                st.info(f"Knowledge graph based on {len(docs)} relevant document chunks, containing {len(graph.nodes())} entities and {len(graph.edges())} relationships.")
                    
                    except Exception as e:
                        st.error(f"Error generating knowledge graph: {str(e)}")
                        
            # çŸ¥è¯†å›¾è°±çš„è¯´æ˜
            with st.expander("What is a Knowledge Graph?"):
                st.markdown("""
                A **Knowledge Graph** is a structured representation of knowledge in the form of a graph, consisting of entities (nodes) and relationships (edges).
                
                In SmartNote AI, knowledge graphs help you:
                - Visually understand key concepts in your documents and their relationships
                - Discover potential knowledge connections
                - Identify important central concepts
                
                How to use: Enter a topic or keyword, and the system will retrieve relevant content from your knowledge base, extract entities and relationships, and display them as an interactive graph.
                """)

# é¡µè„š
st.markdown("---")
st.markdown("*SmartNote AI - Knowledge at your fingertips* ğŸš€")
